import AVFoundation
import UIKit

/// Manages audio session configuration for optimal voice quality with noise cancellation
/// Optimized for VAD (Voice Activity Detection) and ASR (Automatic Speech Recognition)
class AudioSessionManager {
    static let shared = AudioSessionManager()
    
    private init() {}
    
    /// Configure audio session for ASR-optimized voice input
    /// This leverages hardware-level optimizations for Voice Activity Detection and Speech Recognition
    func configureForVoiceInput() {
        let audioSession = AVAudioSession.sharedInstance()
        
        do {
            // STEP 1: Configure audio category and mode
            try audioSession.setCategory(
                .playAndRecord,
                mode: .voiceChat,  // Enables automatic noise suppression, AGC, and echo cancellation
                options: [
                    .defaultToSpeaker,              // Route to speaker (not receiver)
                    .allowBluetoothA2DP,            // High-quality Bluetooth audio
                    .mixWithOthers                  // Allow mixing with other audio (optional)
                ]
            )
            
            // STEP 2: Optimize sample rate for ASR
            // 16kHz is optimal for speech recognition (Nyquist covers human voice 0-8kHz)
            // Most ASR models (Whisper, Google, etc.) downsample to 16kHz anyway
            try audioSession.setPreferredSampleRate(16000.0)
            print("   üìä Requested sample rate: 16kHz (optimal for ASR)")
            
            // STEP 3: Optimize I/O buffer for low latency VAD
            // 10ms buffer = fast VAD response (detects voice start/stop quickly)
            // Lower buffer = better VAD, but higher CPU usage
            try audioSession.setPreferredIOBufferDuration(0.010)  // 10ms
            print("   ‚ö° Buffer duration: 10ms (fast VAD response)")
            
            // STEP 4: Set preferred input channels and polar pattern
            // Mono is best for ASR (reduces data, improves processing speed)
            if let availableInputs = audioSession.availableInputs,
               let builtInMic = availableInputs.first(where: { $0.portType == .builtInMic }) {
                try audioSession.setPreferredInput(builtInMic)
                
                // Configure to use front-facing microphone for beamforming
                let dataSources = builtInMic.dataSources ?? []
                var frontOrBottomSource: AVAudioSessionDataSourceDescription? = nil
                
                for source in dataSources {
                    // Prefer front-facing microphone for optimal user voice capture
                    if source.orientation == AVAudioSession.Orientation.front {
                        frontOrBottomSource = source
                        break
                    }
                }
                
                // If no front mic found, use any available source
                if frontOrBottomSource == nil && !dataSources.isEmpty {
                    frontOrBottomSource = dataSources.first
                }
                
                if let dataSource = frontOrBottomSource {
                    try builtInMic.setPreferredDataSource(dataSource)
                    print("   üéôÔ∏è Using mic: \(dataSource.dataSourceName)")
                    
                    // CRITICAL: Set Cardioid polar pattern for VAD/ASR
                    // Cardioid = heart-shaped pickup (front sensitive, sides reduced, back rejected)
                    if let supportedPatterns = dataSource.supportedPolarPatterns {
                        print("   üìä Supported patterns: \(supportedPatterns.map { $0.rawValue })")
                        
                        // Try to set Cardioid (heart-shaped) pattern
                        if let cardioid = supportedPatterns.first(where: { pattern in
                            pattern == AVAudioSession.PolarPattern.cardioid
                        }) {
                            try dataSource.setPreferredPolarPattern(cardioid)
                            print("   ‚ù§Ô∏è Polar pattern: CARDIOID (optimal for VAD/ASR)")
                            print("      ‚Üí Front: 0¬∞ = 0dB (max sensitivity)")
                            print("      ‚Üí Sides: ¬±90¬∞ = -6dB (reduced)")
                            print("      ‚Üí Back: 180¬∞ = -20dB (rejected)")
                        } else if let subcardioid = supportedPatterns.first(where: { pattern in
                            pattern == AVAudioSession.PolarPattern.subcardioid
                        }) {
                            try dataSource.setPreferredPolarPattern(subcardioid)
                            print("   üíõ Polar pattern: SUBCARDIOID (wide cardioid)")
                        } else {
                            print("   üìç Polar pattern: \(dataSource.selectedPolarPattern?.rawValue ?? "default")")
                        }
                    }
                }
                
                try audioSession.setPreferredInputNumberOfChannels(1)  // Mono for ASR
                print("   üéöÔ∏è Input channels: Mono (optimal for ASR)")
            }
            
            // STEP 5: Configure input gain for optimal dynamic range
            // This helps VAD detect quiet speech vs silence
            if audioSession.isInputGainSettable {
                try audioSession.setInputGain(0.75)  // 75% gain (adjust based on testing)
                print("   üîä Input gain: 75% (optimized for VAD)")
            }
            
            // STEP 6: Activate the session
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
            
            // Log actual configuration (may differ from preferred)
            let actualSampleRate = audioSession.sampleRate
            let actualBufferDuration = audioSession.ioBufferDuration
            let actualChannels = audioSession.inputNumberOfChannels
            
            print("‚úÖ [AudioSession] VAD/ASR Optimized Configuration:")
            print("   üéØ Mode: .voiceChat")
            print("   üìä Sample Rate: \(Int(actualSampleRate))Hz (requested 16kHz)")
            print("   ‚ö° Buffer: \(Int(actualBufferDuration * 1000))ms (requested 10ms)")
            print("   üéöÔ∏è Channels: \(actualChannels) (mono)")
            print("   üîá Noise Cancellation: ‚úÖ Hardware-accelerated")
            print("   üîä Echo Cancellation: ‚úÖ Hardware-accelerated")
            print("   üì° Beamforming: ‚úÖ Microphone array")
            print("   üéôÔ∏è AGC (Auto Gain Control): ‚úÖ Enabled")
            print("   üéØ Optimized for: VAD + ASR")
            
        } catch {
            print("‚ùå [AudioSession] Failed to configure: \(error)")
            fatalError("Cannot configure audio session for voice input: \(error)")
        }
    }
    
    /// Configure for high-quality recording (e.g., for music or podcast)
    func configureForHighQualityRecording() {
        let audioSession = AVAudioSession.sharedInstance()
        
        do {
            try audioSession.setCategory(
                .playAndRecord,
                mode: .measurement,  // Minimal processing, maximum quality
                options: [.defaultToSpeaker]
            )
            
            // Request highest sample rate and I/O buffer duration
            try audioSession.setPreferredSampleRate(48000.0)
            try audioSession.setPreferredIOBufferDuration(0.005)  // 5ms latency
            
            try audioSession.setActive(true)
            
            print("‚úÖ [AudioSession] High-quality recording mode")
            
        } catch {
            print("‚ùå [AudioSession] Failed to configure HQ mode: \(error)")
        }
    }
    
    /// Configure for ultra-high-quality ASR (when WiFi available, not cellular)
    /// 48kHz sample rate for maximum fidelity, then let server downsample
    func configureForHighQualityASR() {
        let audioSession = AVAudioSession.sharedInstance()
        
        do {
            try audioSession.setCategory(
                .playAndRecord,
                mode: .measurement,  // Minimal DSP processing, raw audio
                options: [.defaultToSpeaker, .allowBluetoothA2DP]
            )
            
            // 48kHz for studio-quality capture (server can downsample with better algorithms)
            try audioSession.setPreferredSampleRate(48000.0)
            
            // 5ms buffer for minimal latency
            try audioSession.setPreferredIOBufferDuration(0.005)
            
            // Mono for ASR efficiency
            try audioSession.setPreferredInputNumberOfChannels(1)
            
            try audioSession.setActive(true)
            
            print("‚úÖ [AudioSession] High-Quality ASR mode:")
            print("   üìä Sample Rate: \(Int(audioSession.sampleRate))Hz")
            print("   ‚ö° Buffer: \(Int(audioSession.ioBufferDuration * 1000))ms")
            print("   üéØ Mode: .measurement (raw audio, server-side processing)")
            
        } catch {
            print("‚ùå [AudioSession] Failed to configure HQ ASR: \(error)")
        }
    }
    
    /// Get current audio input level (for VAD visualization)
    /// Returns dB value (-160 to 0), useful for showing "listening" animation
    func getCurrentInputLevel() -> Float {
        let audioSession = AVAudioSession.sharedInstance()
        
        // inputGain ranges from 0.0 to 1.0
        // We can estimate relative level based on this
        if audioSession.isInputAvailable {
            return audioSession.inputGain
        }
        
        return 0.0
    }
    
    /// Monitor audio route changes (e.g., plugging in headphones)
    /// Call this to set up notifications for route changes
    func setupRouteChangeObserver(onChange: @escaping (AVAudioSession.RouteChangeReason) -> Void) {
        NotificationCenter.default.addObserver(
            forName: AVAudioSession.routeChangeNotification,
            object: nil,
            queue: .main
        ) { notification in
            guard let userInfo = notification.userInfo,
                  let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,
                  let reason = AVAudioSession.RouteChangeReason(rawValue: reasonValue) else {
                return
            }
            
            print("üîÑ [AudioSession] Route changed: \(reason)")
            
            switch reason {
            case .newDeviceAvailable:
                print("   ‚ûï New audio device connected")
            case .oldDeviceUnavailable:
                print("   ‚ûñ Audio device disconnected")
            case .categoryChange:
                print("   üîÄ Category changed")
            case .override:
                print("   ‚ö° Route overridden")
            case .wakeFromSleep:
                print("   üåÖ Wake from sleep")
            case .noSuitableRouteForCategory:
                print("   ‚ö†Ô∏è No suitable route")
            case .routeConfigurationChange:
                print("   üîß Route configuration changed")
            default:
                print("   ‚ùì Other reason: \(reason.rawValue)")
            }
            
            onChange(reason)
        }
    }
    
    /// Deactivate audio session when done
    func deactivate() {
        let audioSession = AVAudioSession.sharedInstance()
        
        do {
            try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
            print("‚úÖ [AudioSession] Deactivated")
        } catch {
            print("‚ö†Ô∏è [AudioSession] Failed to deactivate: \(error)")
        }
    }
    
    /// Get current audio route information
    func logAudioRoute() {
        let audioSession = AVAudioSession.sharedInstance()
        
        print("üéôÔ∏è [AudioSession] Current route:")
        
        for input in audioSession.currentRoute.inputs {
            print("   Input: \(input.portName) - \(input.portType.rawValue)")
            print("   Channels: \(input.channels?.count ?? 0)")
        }
        
        for output in audioSession.currentRoute.outputs {
            print("   Output: \(output.portName) - \(output.portType.rawValue)")
        }
    }
}

